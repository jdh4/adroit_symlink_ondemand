{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Welcome to MkDocs","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"admonitions/","title":"Admonitions","text":"<p>Title of the callout</p> <p>Lorem ipsum dolor sit amet, consectetur adipiscing elit. Nulla et euismod nulla. Curabitur feugiat, tortor non consequat finibus, justo purus auctor massa, nec semper lorem quam in massa.</p>"},{"location":"code-example/","title":"Code example","text":"<p>An example of a codeblock for Python:</p> add_numbers.py<pre><code># Function to add two numbers\ndef add_two_numbers(num1, num2):\n    return num1 + num2\n\n# Example usage\nresult = add_two_numbers(5, 3)\nprint('The sum is:', result)\n</code></pre>"},{"location":"jobstats/","title":"Jobstats","text":"<p>Jobstats is a job monitoring platform composed of data exporters, Prometheus, Grafana and the Slurm database whereas <code>jobstats</code> is a command that operates on the Jobstats platform. If you are looking to setup the Jobstats platform then see below and this manuscript.</p> <p>See our PEARC 2023 presentation: \"Jobstats: A Slurm-Compatible Job Monitoring Platform for CPU and GPU Clusters\" (PDF). Here is our PEARC 2024 poster (PDF).</p>"},{"location":"jobstats/#jobstats","title":"jobstats","text":"<p>The <code>jobstats</code> command provides users with a Slurm job efficiency report for a given jobid:</p> <pre><code>$ jobstats 39798795\n\n================================================================================\n                              Slurm Job Statistics\n================================================================================\n         Job ID: 39798795\n  NetID/Account: aturing/math\n       Job Name: sys_logic_ordinals\n          State: COMPLETED\n          Nodes: 2\n      CPU Cores: 48\n     CPU Memory: 256GB (5.3GB per CPU-core)\n           GPUs: 4\n  QOS/Partition: della-gpu/gpu\n        Cluster: della\n     Start Time: Fri Mar 4, 2022 at 1:56 AM\n       Run Time: 18:41:56\n     Time Limit: 4-00:00:00\n\n                              Overall Utilization\n================================================================================\n  CPU utilization  [|||||                                          10%]\n  CPU memory usage [|||                                             6%]\n  GPU utilization  [||||||||||||||||||||||||||||||||||             68%]\n  GPU memory usage [|||||||||||||||||||||||||||||||||              66%]\n\n                              Detailed Utilization\n================================================================================\n  CPU utilization per node (CPU time used/run time)\n      della-i14g2: 1-21:41:20/18-16:46:24 (efficiency=10.2%)\n      della-i14g3: 1-18:48:55/18-16:46:24 (efficiency=9.5%)\n  Total used/runtime: 3-16:30:16/37-09:32:48, efficiency=9.9%\n\n  CPU memory usage per node - used/allocated\n      della-i14g2: 7.9GB/128.0GB (335.5MB/5.3GB per core of 24)\n      della-i14g3: 7.8GB/128.0GB (334.6MB/5.3GB per core of 24)\n  Total used/allocated: 15.7GB/256.0GB (335.1MB/5.3GB per core of 48)\n\n  GPU utilization per node\n      della-i14g2 (GPU 0): 65.7%\n      della-i14g2 (GPU 1): 64.5%\n      della-i14g3 (GPU 0): 72.9%\n      della-i14g3 (GPU 1): 67.5%\n\n  GPU memory usage per node - maximum used/total\n      della-i14g2 (GPU 0): 26.5GB/40.0GB (66.2%)\n      della-i14g2 (GPU 1): 26.5GB/40.0GB (66.2%)\n      della-i14g3 (GPU 0): 26.5GB/40.0GB (66.2%)\n      della-i14g3 (GPU 1): 26.5GB/40.0GB (66.2%)\n\n                                     Notes\n================================================================================\n  * This job only used 6% of the 256GB of total allocated CPU memory. For\n    future jobs, please allocate less memory by using a Slurm directive such\n    as --mem-per-cpu=1G or --mem=10G. This will reduce your queue times and\n    make the resources available to other users. For more info:\n      https://researchcomputing.princeton.edu/support/knowledge-base/memory\n\n  * This job only needed 19% of the requested time which was 4-00:00:00. For\n    future jobs, please request less time by modifying the --time Slurm\n    directive. This will lower your queue times and allow the Slurm job\n    scheduler to work more effectively for all users. For more info:\n      https://researchcomputing.princeton.edu/support/knowledge-base/slurm\n\n  * For additional job metrics including metrics plotted against time:\n    https://mydella.princeton.edu/pun/sys/jobstats  (VPN required off-campus)\n</code></pre> <p>For completed jobs, the data is taken from a call to sacct with several fields including AdminComment. For running jobs, the Prometheus database must be queried.</p> <p>Importantly, the <code>jobstats</code> command is also used to replace <code>smail</code>, which is the Slurm executable used for sending email reports that are based on <code>seff</code>. This means that users receive emails that are the exact output of <code>jobstats</code> including the notes.</p>"},{"location":"jobstats/#installation","title":"Installation","text":"<p>The installation requirements for <code>jobstats</code> are Python 3.6+, Requests 2.20+ and (optionally) blessed 1.17+ which can be used for coloring and styling text.</p> <p>The necessary software can be installed as follows:</p> <pre><code>$ conda create --name js-env python=3.7 requests blessed -c conda-forge\n</code></pre> <p>After setting up the Jobstats platform (see below), to start using the <code>jobstats</code> command on your system, run these commands:</p> <pre><code>$ git clone https://github.com/PrincetonUniversity/jobstats.git\n$ cd jobstats\n# use a text editor to create config.py (see the example configuration file below)\n$ chmod u+x jobstats\n$ ./jobstats 1234567\n</code></pre>"},{"location":"jobstats/#configuration-file","title":"Configuration File","text":"<p>Use <code>config.py</code> as the starting point for your configuration file.</p>"},{"location":"jobstats/#jobstats-platform","title":"Jobstats Platform","text":"<p>Below is an outline of the steps that need to be taken to setup the Jobstats platform for a Slurm cluster:</p> <ul> <li>Switch to cgroup based job accounting from Linux process accounting </li> <li>Setup the exporters: cgroup, node, GPU (on the nodes) and, optionally, GPFS (centrally)</li> <li>Setup the prolog.d and epilog.d scripts on the GPU nodes</li> <li>Setup the Prometheus server and configure it to scrape data from the compute nodes and all configured exporters</li> <li>Setup the slurmctldepilog.sh script for long-term job summary retention</li> <li>Lastly, configure Grafana and Open OnDemand</li> </ul>"},{"location":"jobstats/#exporters","title":"Exporters","text":"<p>We use these four exporters: - node exporter: https://github.com/prometheus/node_exporter - cgroup exporter: https://github.com/plazonic/cgroup_exporter - nvidia gpu exporter: https://github.com/plazonic/nvidia_gpu_prometheus_exporter - gpfs exporter: https://github.com/plazonic/gpfs-exporter</p>"},{"location":"jobstats/#basic-prometheus-configuration","title":"Basic Prometheus Configuration","text":"<p>What follows is an example of production configuration used for the Tiger cluster that has both regular and GPU nodes. <pre><code>---\nglobal:\n  scrape_interval: 15s\n  evaluation_interval: 15s\n  external_labels:\n    monitor: master\n- job_name: Tiger Nodes\n  scrape_interval: 30s\n  scrape_timeout: 30s\n  file_sd_configs:\n  - files:\n    - \"/etc/prometheus/local_files_sd_config.d/tigernodes.json\"\n  metric_relabel_configs:\n  - source_labels:\n    - __name__\n    regex: \"^go_.*\"\n    action: drop\n- job_name: TigerGPU Nodes\n  scrape_interval: 30s\n  scrape_timeout: 30s\n  file_sd_configs:\n  - files:\n    - \"/etc/prometheus/local_files_sd_config.d/tigergpus.json\"\n  metric_relabel_configs:\n  - source_labels:\n    - __name__\n    regex: \"^go_.*\"\n    action: drop\n</code></pre> tigernode.json looks like: <pre><code> [\n   {\n     \"labels\": {\n       \"cluster\": \"tiger\"\n     },\n     \"targets\": [\n       \"tiger-h19c1n10:9100\",\n       \"tiger-h19c1n10:9306\",\n       ...\n     ]\n   }\n ]\n</code></pre> where both node_exporter (port 9100) and cgroup_exporter (port 9306) are listed, for all of tiger's nodes. tigergpus.json looks very similar except that it collects data from nvidia_gpu_prometheus_exporter on port 9445.</p> <p>Note the additional label cluster.</p>"},{"location":"jobstats/#gpu-job-ownership-helper","title":"GPU Job Ownership Helper","text":"<p>In order to correctly track which GPU is assigned to which jobid we use slurm prolog and epilog scripts to create files in <code>/run/gpustat</code> directory named either after GPU ordinal number (0, 1, ..) or, in the case of MIG cards, MIG-UUID. These files contain space separated jobid and uid number of the user. E.g. <pre><code># cat /run/gpustat/MIG-265a219d-a49f-578a-825d-222c72699c16\n45916256 262563\n</code></pre> These two scripts can be found in the slurm directory. For example, slurm/epilog.d/gpustats_helper.sh could be installed as /etc/slurm/epilog.d/gpustats_helper.sh and slurm/prolog.d/gpustats_helper.sh as /etc/slurm/prolog.d/gpustats_helper.sh with these slurm.conf config statements: <pre><code> Prolog=/etc/slurm/prolog.d/*.sh\n Epilog=/etc/slurm/epilog.d/*.sh\n</code></pre></p>"},{"location":"jobstats/#grafana","title":"Grafana","text":"<p>Grafana dashboard json that uses all of the exporters is included in the grafana subdirectory. It expects one parameter, jobid. As it may not be easy to find the time range we also use an ondemand job stats helper that generates the correct time range given a jobid, documented in the next section.</p> <p>The following image illustrates what the dashboard looks like in use:</p> <p></p>"},{"location":"jobstats/#open-ondemand-jobstats-helper","title":"Open OnDemand JobStats Helper","text":"<p>ood-jobstats-helper subdirectory contains an Open OnDemand app that, given a job id, uses sacct to generate a full Grafana URL with job's jobid, start and end times.</p>"},{"location":"jobstats/#generating-job-summaries","title":"Generating Job Summaries","text":"<p>Job summaries, as described above, are generated and stored in the Slurm database at the end of each job by using slurmctld epilog script, e.g.:</p> <pre><code>EpilogSlurmctld=/usr/local/sbin/slurmctldepilog.sh\n</code></pre> <p>The script can be found in the slurm subdirectory, named \"slurmctldepilog.sh\".</p> <p>For processing old jobs where slurmctld epilog script did not run or for jobs where it failed there is a per cluster ingest jobstats service. This is a python based script running on the slurmdbd host, as a systemd timer and service, querying and modifying slurm database directly. The script (ingest_jobstats.py) and systemd timer and service scripts are in the slurm directory. </p> <p>We made heavy use of this script to generate job summaries for older jobs but with the current version of the Epilog script it should not be needed anymore.</p>"},{"location":"jobstats/#job-email-script","title":"Job email script","text":"<p>We use slurm/jobstats_mail.sh as the slurm's Mail program. E.g. from slurm.conf: <pre><code>MailProg=/usr/local/bin/jobstats_mail.sh\n````\nThis will include jobstats information for jobs that have requested email notifications on completion.\n\n### Notes\n\nThe `jobstats` command analyzes each job and produces custom notes at the bottom of the output. Below are several examples:\n</code></pre>   * This job ran on the mig partition where each job is limited to 1 MIG     GPU, 1 CPU-core, 10 GB of GPU memory and 32 GB of CPU memory. A MIG GPU     is about 1/7th as powerful as an A100 GPU. Please continue using the mig     partition when possible. For more info:       https://researchcomputing.princeton.edu/systems/della#gpus</p> <ul> <li> <p>This job completed while only needing 19% of the requested time which     was 2-00:00:00. For future jobs, please decrease the value of the --time     Slurm directive. This will lower your queue times and allow the Slurm     job scheduler to work more effectively for all users. For more info:       https://researchcomputing.princeton.edu/support/knowledge-base/slurm</p> </li> <li> <p>This job did not use the GPU. Please resolve this before running     additional jobs. Wasting resources prevents other users from getting     their work done and it causes your subsequent jobs to have a lower     priority. Is the code GPU-enabled? Please consult the documentation for     the code. For more info:       https://researchcomputing.princeton.edu/support/knowledge-base/gpu-computing</p> </li> <li> <p>This job only used 15% of the 100GB of total allocated CPU memory.     Please consider allocating less memory by using the Slurm directive     --mem-per-cpu=3G or --mem=18G. This will reduce your queue times and     make the resources available to other users. For more info:       https://researchcomputing.princeton.edu/support/knowledge-base/memory</p> </li> <li> <p>This job ran on a large-memory (datascience) node but it only used 117     GB of CPU memory. The large-memory nodes should only be used for jobs     that require more than 190 GB. Please allocate less memory by using the     Slurm directive --mem-per-cpu=9G or --mem=150G. For more info:       https://researchcomputing.princeton.edu/support/knowledge-base/memory</p> </li> <li> <p>The CPU utilization of this job (24%) is approximately equal to 1     divided by the number of allocated CPU-cores (1/4=25%). This suggests     that you may be running a code that can only use 1 CPU-core. If this is     true then allocating more than 1 CPU-core is wasteful. Please consult     the documentation for the software to see if it is parallelized. For     more info:       https://researchcomputing.princeton.edu/support/knowledge-base/parallel-code</p> </li> <li> <p>This job did not use the CPU. This suggests that something went wrong at     the very beginning of the job. Check your Slurm script for errors and     look for useful information in the file slurm-46987157.out if it exists.</p> </li> <li> <p>The Tiger cluster is intended for jobs that require multiple nodes. This     job ran in the serial partition where jobs are assigned the lowest     priority. On Tiger, a job will run in the serial partition if it only     requires 1 node. Consider carrying out this work elsewhere.</p> </li> <li> <p>For additional job metrics including metrics plotted against time:       https://mystellar.princeton.edu/pun/sys/jobstats  (VPN required off-campus)</p> </li> <li> <p>For additional job metrics including metrics plotted against time:       https://stats.rc.princeton.edu  (VPN required off-campus) <pre><code>### JSON Output\n\nOne can also output the raw JSON:\n</code></pre> $ jobstats -j 39798795 | jq {   \"gpus\": 4,   \"nodes\": {     \"della-i14g2\": {       \"cpus\": 24,       \"gpu_total_memory\": {         \"0\": 42949672960,         \"1\": 42949672960       },       \"gpu_used_memory\": {         \"0\": 28453568512,         \"1\": 28453568512       },       \"gpu_utilization\": {         \"0\": 65.7,         \"1\": 64.5       },       \"total_memory\": 137438953472,       \"total_time\": 164480.1,       \"used_memory\": 8444272640     },     \"della-i14g3\": {       \"cpus\": 24,       \"gpu_total_memory\": {         \"0\": 42949672960,         \"1\": 42949672960       },       \"gpu_used_memory\": {         \"0\": 28453634048,         \"1\": 28453634048       },       \"gpu_utilization\": {         \"0\": 72.9,         \"1\": 67.5       },       \"total_memory\": 137438953472,       \"total_time\": 154135.9,       \"used_memory\": 8419606528     }   },   \"total_time\": 67316 } ```</p> </li> </ul>"},{"location":"jobstats/#tools-of-the-jobstats-platform","title":"Tools of the Jobstats Platform","text":"<p>In addition to <code>jobstats</code>, the following software tools build on the Jobstats platform:</p> <ul> <li>gpudash - A command for generating a text-based GPU utilization dashboard   </li> <li>job defense shield - A tool for sending automated email alerts to users  </li> <li>reportseff - A command for displaying Slurm efficiency reports for several jobs at once</li> <li>utilization reports - A tool for sending detailed usage reports to users by email</li> </ul>"},{"location":"jobstats/#users-of-the-jobstats-platform","title":"Users of the Jobstats Platform","text":"<ul> <li>Brown University</li> <li>Free University of Berlin</li> <li>Princeton Computer Science</li> <li>Princeton Research Computing</li> <li>and more</li> </ul>"}]}